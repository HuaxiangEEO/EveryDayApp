/**
 * 操作系统面试题库数据
 * 包含软件工程校招常见的操作系统相关题目和详细答案
 */

export interface Question {
  id: number;
  category: string; // 题目分类
  title: string; // 题目
  answer: string; // 详细答案
  difficulty: 'easy' | 'medium' | 'hard'; // 难度等级
  tags: string[]; // 标签
}

export const questions: Question[] = [
  {
    id: 1,
    category: '进程与线程',
    title: '什么是进程？什么是线程？它们之间有什么区别？',
    difficulty: 'easy',
    tags: ['进程', '线程', '基础概念'],
    answer: `进程（Process）和线程（Thread）是操作系统中的两个重要概念：

**进程（Process）**：
- 进程是程序的一次执行过程，是系统进行资源分配和调度的基本单位
- 每个进程都有独立的地址空间、数据栈和其他用于跟踪执行的辅助数据
- 进程之间相互独立，一个进程崩溃不会影响其他进程
- 进程间通信（IPC）需要通过特殊机制，如管道、消息队列、共享内存等

**线程（Thread）**：
- 线程是进程内的执行单元，是CPU调度的基本单位
- 同一进程内的多个线程共享进程的地址空间和资源
- 线程的创建、切换和销毁开销比进程小得多
- 线程间可以直接访问共享数据，但也需要同步机制避免竞争条件

**主要区别**：
1. **资源占用**：进程拥有独立的地址空间，线程共享进程的地址空间
2. **通信方式**：进程间通信需要IPC机制，线程间可以直接读写共享数据
3. **开销**：进程创建和切换开销大，线程开销小
4. **健壮性**：一个进程崩溃不影响其他进程，但一个线程崩溃可能导致整个进程崩溃
5. **适用场景**：进程适合需要隔离的任务，线程适合需要频繁通信和协作的任务`
  },
  {
    id: 2,
    category: '进程与线程',
    title: '进程的状态有哪些？请描述进程状态转换的过程。',
    difficulty: 'medium',
    tags: ['进程状态', '状态转换'],
    answer: `进程在其生命周期中会经历多种状态，典型的状态包括：

**进程的五种基本状态**：

1. **新建（New）**：进程刚被创建，但尚未被操作系统接受执行
2. **就绪（Ready）**：进程已准备好运行，等待CPU分配时间片
3. **运行（Running）**：进程正在CPU上执行
4. **阻塞（Blocked/Waiting）**：进程等待某个事件发生（如I/O操作完成、信号量等）
5. **终止（Terminated）**：进程执行完毕或被终止

**状态转换过程**：

1. **新建 → 就绪**：操作系统接受进程，将其加入就绪队列
2. **就绪 → 运行**：进程调度器选择该进程，分配CPU时间片
3. **运行 → 就绪**：时间片用完或被更高优先级进程抢占
4. **运行 → 阻塞**：进程请求I/O操作或等待资源，主动放弃CPU
5. **阻塞 → 就绪**：等待的事件发生（如I/O完成），进程重新就绪
6. **运行 → 终止**：进程正常结束或被强制终止

**状态转换图**：
${'```'}
新建 → 就绪 → 运行 → 终止
         ↑      ↓
         ← 阻塞 ←
${'```'}

**关键点**：
- 只有就绪状态的进程才能被调度执行
- 阻塞状态的进程不能直接进入运行状态，必须先转为就绪状态
- 状态转换由操作系统内核控制，确保系统资源的合理分配`
  },
  {
    id: 3,
    category: '进程与线程',
    title: '什么是进程间通信（IPC）？有哪些常见的IPC方式？',
    difficulty: 'medium',
    tags: ['IPC', '进程通信', '同步'],
    answer: `**进程间通信（IPC - Inter-Process Communication）**是指不同进程之间进行数据交换和协调的机制。由于进程拥有独立的地址空间，它们不能直接访问彼此的内存，因此需要特殊的IPC机制。

**常见的IPC方式**：

1. **管道（Pipe）**
   - 半双工通信，数据只能单向流动
   - 只能在有亲缘关系的进程间使用（父子进程）
   - 容量有限，通常为几KB
   - 示例：${'`'}ls | grep "test"${'`'}

2. **命名管道（FIFO）**
   - 可以在无亲缘关系的进程间使用
   - 通过文件系统中的特殊文件实现
   - 仍然半双工

3. **消息队列（Message Queue）**
   - 消息的链表，存储在内核中
   - 支持多个进程读写
   - 可以按消息类型读取
   - 容量受系统限制

4. **共享内存（Shared Memory）**
   - 最快的IPC方式，多个进程映射到同一块物理内存
   - 需要配合信号量等同步机制使用
   - 适合大量数据传输

5. **信号量（Semaphore）**
   - 主要用于进程同步，控制对共享资源的访问
   - 可以用于互斥和同步
   - 有计数信号量和二进制信号量

6. **信号（Signal）**
   - 用于通知进程某个事件已发生
   - 异步通信机制
   - 如SIGKILL、SIGTERM等

7. **套接字（Socket）**
   - 可用于不同机器上的进程通信（网络IPC）
   - 也支持同一机器上的进程通信（Unix域套接字）
   - 功能强大，应用广泛

**选择建议**：
- 大量数据传输：共享内存
- 简单数据传递：管道或消息队列
- 同步控制：信号量
- 网络通信：套接字
- 事件通知：信号`
  },
  {
    id: 4,
    category: '内存管理',
    title: '什么是虚拟内存？它解决了什么问题？',
    difficulty: 'medium',
    tags: ['虚拟内存', '内存管理'],
    answer: `**虚拟内存（Virtual Memory）**是操作系统提供的一种内存管理技术，它使得程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上，它通常被分割成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。

**解决的问题**：

1. **内存不足问题**
   - 程序可以使用的内存空间可以超过实际物理内存大小
   - 通过将暂时不用的数据交换到磁盘，为其他程序腾出空间

2. **内存碎片问题**
   - 虚拟地址空间是连续的，物理内存可以是碎片化的
   - 操作系统负责将虚拟地址映射到物理地址

3. **程序隔离**
   - 每个进程拥有独立的虚拟地址空间
   - 进程无法直接访问其他进程的内存，提高安全性

4. **简化编程**
   - 程序员不需要关心物理内存的分配和释放
   - 可以使用统一的虚拟地址空间

**工作原理**：

1. **分页（Paging）**
   - 将虚拟地址空间和物理内存都划分为固定大小的页（通常4KB）
   - 通过页表（Page Table）建立虚拟页到物理页的映射
   - 当访问的页不在内存中时，触发缺页中断（Page Fault）

2. **页面置换**
   - 当物理内存不足时，需要将某些页换出到磁盘
   - 常用算法：FIFO、LRU（最近最少使用）、LFU（最少使用）等

3. **写时复制（Copy-on-Write）**
   - 多个进程共享同一物理页，只有在写入时才复制
   - 节省内存，提高fork()效率

**优点**：
- 扩大可用内存空间
- 简化内存管理
- 提高系统安全性
- 支持多道程序设计

**缺点**：
- 地址转换需要额外开销
- 页面置换可能影响性能
- 需要额外的硬件支持（MMU）`
  },
  {
    id: 5,
    category: '内存管理',
    title: '请解释页面置换算法，包括FIFO、LRU、LFU等。',
    difficulty: 'hard',
    tags: ['页面置换', '算法', 'LRU'],
    answer: `**页面置换算法**是虚拟内存管理中，当物理内存已满且需要加载新页时，选择哪个页面换出的策略。好的算法应该尽量减少缺页中断次数。

**1. FIFO（First In First Out）**
- **原理**：选择最早进入内存的页面换出
- **实现**：使用队列记录页面进入顺序
- **优点**：实现简单，开销小
- **缺点**：可能出现Belady异常（增加物理页数反而增加缺页率）
- **示例**：
  \`\`\`
  访问序列：1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5
  物理页数：3
  缺页：1,2,3,4,5,3,4 (7次)
  \`\`\`

**2. LRU（Least Recently Used，最近最少使用）**
- **原理**：选择最长时间未被访问的页面换出
- **实现**：
  - 链表实现：每次访问移到链表头，换出链表尾
  - 计数器实现：记录每个页面的访问时间
- **优点**：性能好，符合程序局部性原理
- **缺点**：实现复杂，需要记录访问历史
- **示例**：
  \`\`\`
  访问序列：1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5
  物理页数：3
  缺页：1,2,3,4,5,3,4 (7次)
  \`\`\`

**3. LFU（Least Frequently Used，最少使用）**
- **原理**：选择访问频率最低的页面换出
- **实现**：为每个页面维护访问计数器
- **优点**：适合访问频率差异明显的场景
- **缺点**：可能淘汰最近频繁访问但总体频率低的页面

**4. OPT（Optimal，最优算法）**
- **原理**：选择未来最长时间不会被访问的页面
- **优点**：理论上最优，缺页率最低
- **缺点**：需要预知未来访问序列，实际无法实现
- **用途**：作为其他算法的性能基准

**5. Clock算法（时钟算法）**
- **原理**：LRU的近似实现，使用引用位（Reference Bit）
- **实现**：
  - 页面组织成环形链表
  - 访问时设置引用位为1
  - 置换时扫描，遇到引用位1则置0继续，遇到0则换出
- **优点**：实现简单，性能接近LRU
- **缺点**：可能不够精确

**6. 改进的Clock算法（二次机会算法）**
- **原理**：Clock算法的改进，增加修改位（Dirty Bit）
- **实现**：优先换出未修改的页面（避免写回磁盘）
- **优点**：减少I/O操作

**性能比较**（一般情况）：
OPT < LRU < Clock < FIFO

**实际应用**：
- Linux使用改进的LRU算法
- Windows使用工作集和页面置换的组合策略
- 现代操作系统通常结合多种策略，根据页面特性选择`
  },
  {
    id: 6,
    category: '文件系统',
    title: '什么是文件系统？常见的文件系统有哪些？',
    difficulty: 'easy',
    tags: ['文件系统', '存储'],
    answer: `**文件系统（File System）**是操作系统用于管理存储设备（如硬盘、SSD）上数据存储和检索的方法和数据结构。它定义了文件的命名、存储、组织和访问方式。

**文件系统的主要功能**：

1. **文件管理**：创建、删除、重命名文件
2. **目录管理**：组织文件层次结构
3. **存储空间管理**：分配和回收磁盘空间
4. **访问控制**：权限管理和安全控制
5. **数据一致性**：确保数据不丢失、不损坏

**常见的文件系统**：

**Windows系统**：
1. **FAT32**
   - 兼容性好，支持多种操作系统
   - 文件大小限制4GB，分区大小限制32GB（实际可更大）
   - 适合U盘和小容量存储

2. **NTFS（New Technology File System）**
   - Windows默认文件系统
   - 支持大文件、大分区、权限控制、加密、压缩
   - 日志功能提高可靠性
   - 文件大小限制16EB（理论值）

3. **exFAT**
   - 专为闪存设备设计
   - 支持大文件和大分区
   - 兼容性好，适合移动存储设备

**Linux系统**：
1. **ext2/ext3/ext4**
   - ext2：早期Linux文件系统，无日志
   - ext3：ext2的日志版本
   - ext4：ext3的改进版，支持更大文件和分区，性能更好
   - 目前ext4是主流Linux发行版的默认文件系统

2. **XFS**
   - 高性能文件系统，适合大文件和大容量存储
   - 支持在线扩容
   - 常用于服务器环境

3. **Btrfs**
   - 支持写时复制、快照、压缩、子卷等高级特性
   - 类似ZFS的功能
   - 仍在发展中

**macOS系统**：
1. **HFS+**
   - macOS的传统文件系统
   - 逐渐被APFS取代

2. **APFS（Apple File System）**
   - macOS的现代文件系统
   - 支持快照、克隆、加密
   - 针对SSD优化

**网络文件系统**：
- **NFS（Network File System）**：Unix/Linux网络文件系统
- **SMB/CIFS**：Windows网络文件系统
- **AFS**：分布式文件系统

**文件系统的关键概念**：
- **inode**：索引节点，存储文件的元数据（权限、大小、位置等）
- **目录项（dentry）**：目录中的条目，连接文件名和inode
- **超级块（superblock）**：文件系统的元数据
- **块（block）**：文件系统的最小存储单位

**选择建议**：
- Windows：NTFS（本地），exFAT（移动设备）
- Linux：ext4（通用），XFS（大文件/服务器）
- macOS：APFS
- 跨平台：exFAT或FAT32`
  },
  {
    id: 7,
    category: '死锁',
    title: '什么是死锁？产生死锁的必要条件是什么？如何预防和避免死锁？',
    difficulty: 'hard',
    tags: ['死锁', '同步', '并发'],
    answer: `**死锁（Deadlock）**是指两个或多个进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。

**产生死锁的四个必要条件**（必须同时满足）：

1. **互斥条件（Mutual Exclusion）**
   - 资源不能被多个进程同时使用，只能互斥访问
   - 如打印机、文件等

2. **请求和保持条件（Hold and Wait）**
   - 进程在持有至少一个资源的同时，请求其他资源
   - 如果请求的资源被占用，进程不会释放已持有的资源

3. **不可抢占条件（No Preemption）**
   - 资源不能被强制从持有它的进程手中夺走
   - 只能由持有资源的进程主动释放

4. **循环等待条件（Circular Wait）**
   - 存在一个进程-资源的环形链
   - 如：P1等待P2持有的资源，P2等待P3持有的资源，P3等待P1持有的资源

**死锁预防（Prevention）**：
通过破坏死锁的四个必要条件之一来预防死锁：

1. **破坏互斥条件**
   - 让资源可共享访问
   - 但很多资源本质上是互斥的（如打印机），难以实现

2. **破坏请求和保持条件**
   - **方法1**：进程开始前必须申请所有需要的资源
   - **方法2**：进程不能持有资源时请求新资源，必须先释放所有资源
   - **缺点**：资源利用率低，可能导致饥饿

3. **破坏不可抢占条件**
   - 允许抢占资源
   - 实现复杂，可能影响系统稳定性

4. **破坏循环等待条件**
   - **资源有序分配**：给所有资源编号，进程必须按编号顺序申请资源
   - 这是最常用和有效的方法
   - **示例**：
     \`\`\`
     资源编号：打印机=1，扫描仪=2，磁盘=3
     进程必须按1→2→3的顺序申请，不能先申请2再申请1
     \`\`\`

**死锁避免（Avoidance）**：
在资源分配时动态检查，确保不会进入不安全状态：

1. **银行家算法（Banker's Algorithm）**
   - 模拟资源分配，检查分配后系统是否处于安全状态
   - 只有安全时才分配资源
   - **安全状态**：存在一个安全序列，使得所有进程都能完成
   - **不安全状态**：可能导致死锁，但不一定发生死锁

2. **资源分配图算法**
   - 使用有向图表示进程和资源的关系
   - 检测是否存在环路

**死锁检测和恢复**：
如果允许死锁发生，则需要检测和恢复：

1. **死锁检测**
   - 定期检查资源分配图是否存在环路
   - 使用深度优先搜索（DFS）检测环路

2. **死锁恢复**
   - **进程终止**：终止一个或多个死锁进程
   - **资源抢占**：从某些进程抢占资源分配给其他进程
   - 需要选择牺牲的进程（如优先级最低、执行时间最短等）

**实际应用**：
- **数据库系统**：使用超时机制和死锁检测
- **操作系统**：通常采用死锁预防（资源有序分配）和死锁检测结合
- **Java并发**：使用锁超时、死锁检测工具（jstack）

**示例代码（死锁场景）**：
\`\`\`java
// 线程1
synchronized(resourceA) {
    synchronized(resourceB) { ... }
}

// 线程2
synchronized(resourceB) {
    synchronized(resourceA) { ... }
}
\`\`\`

**避免方法**：按相同顺序获取锁（如都先获取resourceA再获取resourceB）`
  },
  {
    id: 8,
    category: '同步与互斥',
    title: '什么是信号量（Semaphore）？请解释P操作和V操作。',
    difficulty: 'medium',
    tags: ['信号量', '同步', 'PV操作'],
    answer: `**信号量（Semaphore）**是操作系统提供的一种同步原语，用于控制多个进程或线程对共享资源的访问。它由荷兰计算机科学家Dijkstra提出。

**信号量的基本概念**：

信号量是一个整型变量S，除了初始化外，只能通过两个原子操作来访问：
- **P操作（Wait/Proberen）**：申请资源
- **V操作（Signal/Verhogen）**：释放资源

**P操作（Wait操作）**：
\`\`\`
P(S):
    while S <= 0 do
        ; // 忙等待（busy waiting）
    S := S - 1;
\`\`\`

**V操作（Signal操作）**：
\`\`\`
V(S):
    S := S + 1;
\`\`\`

**信号量的类型**：

1. **二进制信号量（Binary Semaphore/Mutex）**
   - 值只能是0或1
   - 用于互斥访问，实现临界区保护
   - 也称为互斥锁（Mutex）

2. **计数信号量（Counting Semaphore）**
   - 值可以是任意非负整数
   - 表示可用资源的数量
   - 用于控制对多个资源的访问

**信号量的应用**：

**1. 互斥（Mutex）**
\`\`\`
semaphore mutex = 1; // 二进制信号量

// 进程P1
P(mutex);
    // 临界区代码
V(mutex);

// 进程P2
P(mutex);
    // 临界区代码
V(mutex);
\`\`\`

**2. 同步（Synchronization）**
\`\`\`
semaphore S = 0; // 初始化为0

// 进程P1（生产者）
// 执行某些操作
V(S); // 通知P2

// 进程P2（消费者）
P(S); // 等待P1完成
// 继续执行
\`\`\`

**3. 资源计数**
\`\`\`
semaphore empty = N; // 空缓冲区数量
semaphore full = 0;  // 满缓冲区数量
semaphore mutex = 1; // 互斥锁

// 生产者
P(empty);  // 等待空缓冲区
P(mutex);  // 进入临界区
    // 放入数据
V(mutex);  // 离开临界区
V(full);   // 增加满缓冲区计数

// 消费者
P(full);   // 等待满缓冲区
P(mutex);  // 进入临界区
    // 取出数据
V(mutex);  // 离开临界区
V(empty);  // 增加空缓冲区计数
\`\`\`

**阻塞式实现**：

实际系统中，P操作通常使用阻塞队列而不是忙等待：
\`\`\`
P(S):
    S := S - 1;
    if S < 0 then
        // 将当前进程加入等待队列
        block(); // 阻塞当前进程

V(S):
    S := S + 1;
    if S <= 0 then
        // 从等待队列唤醒一个进程
        wakeup(); // 唤醒等待的进程
\`\`\`

**信号量的优缺点**：

**优点**：
- 功能强大，可以解决多种同步问题
- 可以用于进程间和线程间同步
- 支持多个资源的计数

**缺点**：
- 使用不当容易出错（如忘记V操作导致死锁）
- 可能导致优先级反转问题
- 实现相对复杂

**现代实现**：
- **POSIX信号量**：\`sem_wait()\`, \`sem_post()\`
- **Java**：\`Semaphore\`类
- **Python**：\`threading.Semaphore\`
- **Linux**：\`semop()\`系统调用

**注意事项**：
1. P和V操作必须是原子操作
2. 成对使用P和V操作
3. 避免死锁：按相同顺序获取多个信号量
4. 避免饥饿：使用公平的信号量实现`
  },
  {
    id: 9,
    category: '调度算法',
    title: '请介绍常见的进程调度算法，包括FCFS、SJF、优先级调度、时间片轮转等。',
    difficulty: 'medium',
    tags: ['调度算法', '进程调度'],
    answer: `**进程调度算法**是操作系统决定哪个进程获得CPU使用权的策略。好的调度算法应该平衡多个目标：公平性、响应时间、吞吐量、CPU利用率等。

**1. 先来先服务（FCFS - First Come First Served）**
- **原理**：按照进程到达就绪队列的顺序分配CPU
- **特点**：
  - 非抢占式，一旦进程获得CPU，直到完成或阻塞
  - 实现简单，公平
- **优点**：简单易懂，公平
- **缺点**：
  - 短进程可能被长进程阻塞（护航效应）
  - 平均等待时间长
  - 不适合交互式系统
- **示例**：
  \`\`\`
  进程  到达时间  执行时间
  P1    0        24
  P2    1        3
  P3    2        3
  
  执行顺序：P1(0-24) → P2(24-27) → P3(27-30)
  平均等待时间：(0 + 23 + 25) / 3 = 16
  \`\`\`

**2. 最短作业优先（SJF - Shortest Job First）**
- **原理**：优先调度执行时间最短的进程
- **变种**：
  - **非抢占式SJF**：进程一旦开始执行直到完成
  - **抢占式SJF（SRTF）**：新来的短进程可以抢占CPU
- **优点**：
  - 平均等待时间最短（理论上）
  - 吞吐量高
- **缺点**：
  - 需要预知进程执行时间（实际难以实现）
  - 可能导致长进程饥饿
- **示例**：
  \`\`\`
  进程  到达时间  执行时间
  P1    0        8
  P2    1        4
  P3    2        9
  P4    3        5
  
  非抢占SJF：P1(0-1) → P2(1-5) → P4(5-10) → P1(10-18) → P3(18-27)
  \`\`\`

**3. 优先级调度（Priority Scheduling）**
- **原理**：每个进程分配一个优先级，优先调度优先级高的进程
- **优先级确定**：
  - 静态优先级：进程创建时确定，不变
  - 动态优先级：根据等待时间、执行时间等动态调整
- **变种**：
  - **非抢占式**：高优先级进程等待当前进程完成
  - **抢占式**：高优先级进程可以抢占CPU
- **优点**：灵活，可以体现进程重要性
- **缺点**：低优先级进程可能饥饿
- **解决方案**：老化（Aging）技术，逐渐提高等待时间长的进程优先级

**4. 时间片轮转（RR - Round Robin）**
- **原理**：每个进程分配一个时间片（Time Quantum），时间片用完后切换到下一个进程
- **特点**：
  - 抢占式调度
  - 适合交互式系统
  - 时间片大小很重要：
    - 太大：退化为FCFS
    - 太小：上下文切换开销大
- **优点**：
  - 公平，每个进程都能获得CPU时间
  - 响应时间短
- **缺点**：
  - 平均等待时间可能较长
  - 时间片选择困难
- **示例**：
  \`\`\`
  进程  执行时间  时间片=4
  P1    24
  P2    3
  P3    3
  
  执行：P1(0-4) → P2(4-7) → P3(7-10) → P1(10-14) → ...
  \`\`\`

**5. 多级队列调度（Multilevel Queue）**
- **原理**：将就绪队列分成多个队列，每个队列有自己的调度算法
- **特点**：
  - 不同队列可以有不同的优先级
  - 队列间可以固定优先级或时间片分配
- **示例**：
  \`\`\`
  系统进程队列（高优先级，FCFS）
  交互进程队列（中优先级，RR）
  批处理队列（低优先级，SJF）
  \`\`\`

**6. 多级反馈队列（Multilevel Feedback Queue）**
- **原理**：多级队列的改进，允许进程在队列间移动
- **规则**：
  - 新进程进入最高优先级队列
  - 时间片用完未完成，降级到下一队列
  - 低优先级队列时间片通常更大
- **优点**：
  - 短进程优先处理
  - 长进程不会完全饥饿
  - 适应不同类型的进程
- **缺点**：实现复杂

**7. 最短剩余时间优先（SRTF - Shortest Remaining Time First）**
- **原理**：抢占式SJF，总是调度剩余执行时间最短的进程
- **优点**：平均等待时间最短
- **缺点**：需要预知剩余执行时间

**性能指标**：
- **周转时间** = 完成时间 - 到达时间
- **等待时间** = 周转时间 - 执行时间
- **响应时间** = 首次获得CPU时间 - 到达时间

**实际应用**：
- **Linux**：使用CFS（完全公平调度器），基于虚拟运行时间
- **Windows**：多级反馈队列，支持优先级提升
- **实时系统**：EDF（最早截止时间优先）、RMS（速率单调调度）`
  },
  {
    id: 10,
    category: 'I/O管理',
    title: '请解释I/O的几种方式：程序控制I/O、中断驱动I/O、DMA、通道控制。',
    difficulty: 'hard',
    tags: ['I/O', 'DMA', '中断'],
    answer: `**I/O方式**是指CPU与外部设备进行数据交换的方法。随着计算机系统的发展，I/O方式从简单到复杂，效率不断提高。

**1. 程序控制I/O（Programmed I/O / Polling）**

**原理**：
- CPU不断查询设备状态寄存器，检查设备是否准备好
- 设备准备好后，CPU执行数据传输
- CPU全程参与，处于忙等待状态

**特点**：
- 实现简单
- CPU利用率低，大量时间浪费在轮询上
- 适合简单、快速的设备

**伪代码**：
\`\`\`
while (设备状态 != 就绪) {
    // 忙等待
}
// 执行I/O操作
\`\`\`

**2. 中断驱动I/O（Interrupt-Driven I/O）**

**原理**：
- CPU启动I/O操作后，继续执行其他任务
- 设备完成I/O操作后，向CPU发送中断信号
- CPU响应中断，处理I/O完成事件

**工作流程**：
1. CPU向设备控制器发出I/O命令
2. CPU继续执行其他进程
3. 设备完成I/O操作，发送中断信号
4. CPU保存当前上下文，执行中断处理程序
5. 中断处理完成后，恢复原进程执行

**特点**：
- CPU利用率提高，不需要忙等待
- 适合慢速设备
- 每次数据传输都需要CPU参与，仍有开销

**优点**：
- CPU和I/O设备可以并行工作
- 响应及时

**缺点**：
- 每次传输都需要中断，CPU开销较大
- 不适合高速、大批量数据传输

**3. DMA（Direct Memory Access，直接内存访问）**

**原理**：
- 在内存和设备之间建立直接数据通路
- DMA控制器代替CPU执行数据传输
- 只在传输开始和结束时需要CPU参与

**工作流程**：
1. CPU设置DMA控制器（源地址、目标地址、传输长度）
2. CPU启动DMA传输，继续执行其他任务
3. DMA控制器直接访问内存，完成数据传输
4. 传输完成后，DMA控制器发送中断通知CPU

**特点**：
- CPU只在传输开始和结束时参与
- 数据传输过程中CPU可以执行其他任务
- 适合大批量数据传输

**优点**：
- 大幅减少CPU开销
- 提高系统整体性能
- 支持高速数据传输

**缺点**：
- 需要额外的DMA控制器硬件
- 可能造成内存总线竞争

**DMA传输模式**：
- **单字模式**：每次传输一个字，传输后释放总线
- **块模式**：连续传输整个数据块，传输完成后释放总线
- **请求模式**：设备请求时才传输

**4. 通道控制（Channel Control）**

**原理**：
- 通道是专门处理I/O的处理器，功能比DMA控制器更强
- 可以执行通道程序，独立完成复杂的I/O操作
- CPU只需发出I/O指令，通道自动完成所有操作

**通道类型**：
1. **字节多路通道**：连接多个慢速设备，分时共享
2. **选择通道**：连接高速设备，一次只服务一个设备
3. **数组多路通道**：结合前两者特点

**特点**：
- CPU参与最少，只需发出命令
- 通道可以执行复杂的I/O操作序列
- 适合大型计算机系统

**优点**：
- CPU完全解放，专注于计算任务
- 可以处理复杂的I/O操作
- 适合I/O密集型应用

**缺点**：
- 硬件成本高
- 实现复杂

**性能对比**：

| I/O方式 | CPU参与程度 | 适用场景 | 效率 |
|---------|------------|---------|------|
| 程序控制I/O | 全程参与 | 简单快速设备 | 低 |
| 中断驱动I/O | 每次传输参与 | 慢速设备 | 中 |
| DMA | 开始和结束参与 | 高速大批量传输 | 高 |
| 通道控制 | 最小参与 | 大型系统，复杂I/O | 最高 |

**现代系统**：
- **个人计算机**：主要使用中断驱动I/O和DMA
- **服务器**：使用DMA和智能I/O控制器
- **大型机**：可能使用通道控制

**实际应用**：
- **磁盘I/O**：DMA传输
- **网络I/O**：中断驱动 + DMA
- **键盘鼠标**：中断驱动
- **显卡**：DMA（显存直接访问）`
  },
  {
    id: 11,
    category: '系统调用',
    title: '什么是系统调用？系统调用和普通函数调用有什么区别？',
    difficulty: 'medium',
    tags: ['系统调用', '内核'],
    answer: `**系统调用（System Call）**是操作系统提供给应用程序的接口，允许应用程序请求操作系统内核的服务。它是用户空间和内核空间之间的桥梁。

**系统调用的作用**：
- 提供对硬件资源的访问（文件、网络、内存等）
- 提供进程管理功能（创建进程、线程等）
- 提供系统服务（时间、随机数等）
- 保护系统安全，防止应用程序直接访问硬件

**系统调用和普通函数调用的区别**：

| 特性 | 普通函数调用 | 系统调用 |
|------|------------|---------|
| **执行环境** | 用户空间 | 内核空间 |
| **调用方式** | 直接跳转 | 通过中断/陷阱 |
| **开销** | 小 | 较大（需要上下文切换） |
| **权限** | 用户权限 | 内核权限 |
| **可移植性** | 依赖库 | 操作系统相关 |
| **错误处理** | 返回值/异常 | 返回值（errno） |

**系统调用的执行过程**：

1. **用户程序调用库函数**（如\`open()\`）
2. **库函数准备参数**，调用系统调用接口
3. **触发软中断/陷阱**（如Linux的\`int 0x80\`或\`syscall\`指令）
4. **CPU切换到内核模式**，保存用户态上下文
5. **执行系统调用处理程序**，根据系统调用号查找处理函数
6. **在内核空间执行相应操作**
7. **返回结果**，恢复用户态上下文
8. **返回到用户程序**

**常见的系统调用分类**：

1. **进程控制**
   - \`fork()\`：创建子进程
   - \`exec()\`：执行程序
   - \`exit()\`：终止进程
   - \`wait()\`：等待子进程

2. **文件操作**
   - \`open()\`：打开文件
   - \`read()\`：读文件
   - \`write()\`：写文件
   - \`close()\`：关闭文件

3. **设备操作**
   - \`ioctl()\`：设备控制
   - \`read()\`/\`write()\`：设备读写

4. **信息维护**
   - \`getpid()\`：获取进程ID
   - \`gettimeofday()\`：获取时间
   - \`sysinfo()\`：获取系统信息

5. **通信**
   - \`pipe()\`：创建管道
   - \`shmget()\`：共享内存
   - \`socket()\`：网络通信

**系统调用的实现方式**：

1. **中断方式**（传统）
   - 使用软中断指令（如\`int 0x80\`）
   - 通过中断描述符表（IDT）跳转到内核处理程序

2. **syscall指令**（现代）
   - x86-64使用\`syscall\`指令
   - 性能更好，不需要查表

3. **vsyscall/vDSO**（虚拟系统调用）
   - 某些系统调用映射到用户空间
   - 避免进入内核，提高性能
   - 如\`gettimeofday()\`

**系统调用开销**：

系统调用需要：
- 用户态到内核态切换
- 参数传递和验证
- 内核执行操作
- 内核态到用户态切换

**优化方法**：
- 批量系统调用（如\`readv()\`/\`writev()\`）
- 使用vDSO避免某些系统调用
- 异步I/O（如\`aio_read()\`）

**示例代码**：

\`\`\`c
// C语言中的系统调用
#include <unistd.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>

int main() {
    // open()是系统调用
    int fd = open("file.txt", O_RDONLY);
    if (fd < 0) {
        // 错误处理
        return 1;
    }
    
    char buffer[1024];
    // read()是系统调用
    ssize_t n = read(fd, buffer, sizeof(buffer));
    
    // close()是系统调用
    close(fd);
    return 0;
}
\`\`\`

**POSIX标准**：
- POSIX定义了标准的系统调用接口
- 不同Unix系统（Linux、macOS、BSD）实现相同接口
- 提高程序可移植性

**Windows系统调用**：
- Windows使用不同的系统调用接口（Win32 API）
- 底层通过\`syscall\`指令或\`int 2Eh\`实现
- 应用程序通常通过Win32 API而不是直接系统调用`
  },
  {
    id: 12,
    category: '缓存',
    title: '什么是缓存？请解释CPU缓存的多级层次结构。',
    difficulty: 'medium',
    tags: ['缓存', 'CPU', '性能'],
    answer: `**缓存（Cache）**是位于CPU和主内存之间的高速存储器，用于存储最近使用的数据和指令，以减少访问主内存的次数，提高系统性能。

**为什么需要缓存？**

**存储层次结构的速度差异**：
- CPU寄存器：< 1ns
- L1缓存：~1ns
- L2缓存：~3-10ns
- L3缓存：~10-20ns
- 主内存（DRAM）：~50-100ns
- 磁盘：~5-10ms

速度差异可达数百倍甚至数千倍，缓存可以显著减少平均访问时间。

**CPU缓存的多级层次结构**：

现代CPU通常采用三级缓存结构：

**1. L1缓存（一级缓存）**
- **位置**：最接近CPU核心，集成在CPU芯片内
- **容量**：通常32KB-64KB（指令缓存）+ 32KB-64KB（数据缓存）
- **速度**：最快，1-3个时钟周期
- **特点**：
  - 分为指令缓存（I-Cache）和数据缓存（D-Cache）
  - 每个CPU核心独享
  - 访问延迟最低

**2. L2缓存（二级缓存）**
- **位置**：位于L1和L3之间
- **容量**：通常256KB-1MB
- **速度**：较L1慢，约10-20个时钟周期
- **特点**：
  - 指令和数据共享
  - 每个CPU核心独享（或小核心共享）
  - 作为L1和L3之间的缓冲

**3. L3缓存（三级缓存）**
- **位置**：位于L2和主内存之间
- **容量**：通常2MB-32MB（服务器CPU可达64MB+）
- **速度**：较L2慢，约40-75个时钟周期
- **特点**：
  - 所有CPU核心共享
  - 容量最大
  - 减少访问主内存的频率

**缓存的工作原理**：

**1. 缓存命中（Cache Hit）**
- 需要的数据在缓存中
- 直接从缓存读取，速度快

**2. 缓存未命中（Cache Miss）**
- 需要的数据不在缓存中
- 需要从下一级缓存或主内存加载
- 加载时可能替换缓存中的旧数据

**缓存替换策略**：
- **LRU（最近最少使用）**：最常用
- **FIFO（先进先出）**
- **随机替换**

**缓存写策略**：

**1. 写直达（Write-Through）**
- 同时写入缓存和主内存
- 简单但速度慢

**2. 写回（Write-Back）**
- 只写入缓存，标记为"脏"
- 替换时才写回主内存
- 速度快但实现复杂

**3. 写分配（Write-Allocate）**
- 写未命中时，先加载到缓存再写

**4. 写不分配（Write-No-Allocate）**
- 写未命中时，直接写主内存

**缓存一致性（Cache Coherence）**：

多核系统中，多个核心的缓存可能包含同一内存地址的数据，需要保证一致性。

**MESI协议**（常用）：
- **M（Modified）**：已修改，只在本核心缓存中
- **E（Exclusive）**：独占，只在本核心缓存中，未修改
- **S（Shared）**：共享，多个核心缓存中都有
- **I（Invalid）**：无效

**缓存性能指标**：

1. **命中率（Hit Rate）**
   - 缓存命中次数 / 总访问次数
   - 通常L1 > 90%，L2 > 80%，L3 > 60%

2. **平均访问时间**
   \`\`\`
   T_avg = Hit_Rate × T_cache + (1 - Hit_Rate) × T_memory
   \`\`\`

3. **缺失率（Miss Rate）**
   - 1 - 命中率

**影响缓存性能的因素**：

1. **局部性原理**
   - **时间局部性**：最近访问的数据很可能再次访问
   - **空间局部性**：相邻地址的数据很可能被访问
   - 程序具有良好的局部性时，缓存效果好

2. **缓存行大小（Cache Line）**
   - 通常64字节
   - 一次加载一整行，利用空间局部性

3. **关联度（Associativity）**
   - **直接映射**：每个内存块只能映射到一个缓存位置
   - **组相联**：每个内存块可以映射到一组缓存位置
   - **全相联**：可以映射到任意缓存位置

**实际应用**：

- **数据库**：设计查询算法考虑缓存友好性
- **编程优化**：
  - 循环顺序访问数组（利用空间局部性）
  - 减少随机访问
  - 数据结构对齐（避免缓存行分割）
- **操作系统**：页面置换算法考虑缓存效果

**示例**：
\`\`\`c
// 缓存友好的代码
for (int i = 0; i < n; i++) {
    sum += array[i]; // 顺序访问，缓存友好
}

// 缓存不友好的代码
for (int i = 0; i < n; i++) {
    sum += array[random_index[i]]; // 随机访问，缓存不友好
}
\`\`\``
  }
];

/**
 * 获取所有分类
 */
export function getCategories(): string[] {
  return Array.from(new Set(questions.map(q => q.category)));
}

/**
 * 根据分类筛选题目
 */
export function getQuestionsByCategory(category: string): Question[] {
  return questions.filter(q => q.category === category);
}

/**
 * 根据难度筛选题目
 */
export function getQuestionsByDifficulty(difficulty: Question['difficulty']): Question[] {
  return questions.filter(q => q.difficulty === difficulty);
}

/**
 * 搜索题目
 */
export function searchQuestions(keyword: string): Question[] {
  const lowerKeyword = keyword.toLowerCase();
  return questions.filter(q => 
    q.title.toLowerCase().includes(lowerKeyword) ||
    q.answer.toLowerCase().includes(lowerKeyword) ||
    q.tags.some(tag => tag.toLowerCase().includes(lowerKeyword))
  );
}
